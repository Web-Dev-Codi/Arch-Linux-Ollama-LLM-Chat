[app]
title = "OllamaTerm"
class = "ollamaterm"
connection_check_interval_seconds = 15

[ollama]
host = "http://localhost:11434"
model = "llama3.2"
models = ["llama3.2", "qwen2.5", "mistral"]
timeout = 120
system_prompt = "You are a helpful assistant."
max_history_messages = 200
max_context_tokens = 4096
pull_model_on_start = true

[ui]
font_size = 14
background_color = "#1a1b26"
user_message_color = "#7aa2f7"
assistant_message_color = "#9ece6a"
border_color = "#565f89"
show_timestamps = true
stream_chunk_size = 8

[keybinds]
send_message = "ctrl+enter"
new_conversation = "ctrl+n"
quit = "ctrl+q"
scroll_up = "ctrl+k"
scroll_down = "ctrl+j"
command_palette = "ctrl+p"
toggle_model_picker = "ctrl+m"
save_conversation = "ctrl+s"
load_conversation = "ctrl+l"
export_conversation = "ctrl+e"
search_messages = "ctrl+f"
copy_last_message = "ctrl+y"

[security]
allow_remote_hosts = false
allowed_hosts = ["localhost", "127.0.0.1", "::1"]

[logging]
level = "INFO"
structured = true
log_to_file = false
log_file_path = "~/.local/state/ollama-chat/app.log"

[persistence]
enabled = false
directory = "~/.local/state/ollama-chat/conversations"
metadata_path = "~/.local/state/ollama-chat/conversations/index.json"

[capabilities]
# Enable chain-of-thought reasoning (think=True in API call).
# Supported by models like qwen3, deepseek-r1, deepseek-v3.1.
think = true

# Show the reasoning trace in the assistant bubble (plain preformatted text).
show_thinking = true

# Enable tool calling and the agent loop.
# The model may call tools multiple times before producing a final answer.
tools_enabled = true

# Enable Ollama's built-in web_search and web_fetch tools.
# Requires OLLAMA_API_KEY to be set (or web_search_api_key below).
# See: https://ollama.com/settings/keys
web_search_enabled = false

# API key for Ollama web search. If empty, falls back to OLLAMA_API_KEY env var.
web_search_api_key = ""

# Enable image attachments for vision-capable models (e.g. gemma3, llava).
# Use /image <path> in the input box or click the Attach button.
vision_enabled = true

# Maximum number of tool-call iterations per message before stopping the loop.
max_tool_iterations = 10
